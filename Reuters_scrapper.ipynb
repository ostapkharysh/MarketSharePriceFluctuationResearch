{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.reuters.com/resources/archive/us/{}{}{}.html\"\n",
    "ag = \"Reuters\"\n",
    "#reuters_db = '/home/ostapkharysh/Documents/bt_data/DB/Reuters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import datetime\n",
    "#from db_manager import *\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from manager import *\n",
    "from threading import Lock\n",
    "mutex = Lock()\n",
    "\n",
    "years = ['2014',] #'2015']#, '2014', '2015', '2016', '2017']\n",
    "months = ['01', '02', '03', '04', '05']#, '06', '07', '08', '09', '10', '11', '12']\n",
    "days = ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    \n",
    "exec(open(\"db_management/DB.py\").read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<db_management.DB.Agency object at 0x7f58f5449b38>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There is already a Table with such name: Reuters'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_agency(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(link):\n",
    "    try:\n",
    "        r = requests.get(link)\n",
    "        #print(r.raise_for_status())\n",
    "        soup = BS(r.content, 'html.parser')\n",
    "        head = soup.html.title.string.strip().split(\" | \")[0]\n",
    "        text = '\\n'.join([e.get_text() for e in soup.find_all('p')])\n",
    "        #print(text)\n",
    "        #print(head)\n",
    "        return head, text\n",
    "    \n",
    "    except HTTPError:\n",
    "        print(\"No article found by this link!\", link)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(link_time, date): \n",
    "    try:\n",
    "    #for link_time in links_times:\n",
    "        title,text = get_text(link_time[0])\n",
    "        time = link_time[1]\n",
    "        #print(time)\n",
    "        date = datetime.datetime.strptime(\"{} {} {} {}\".format(month, day, year, time), '%b %d %Y %I:%M%p')\n",
    "        #print(str(date))\n",
    "        #print(str(date)+'\\n'+title+'\\n'+text+'\\n'+link_time[0])\n",
    "        #print(str(date)+'\\n'+title+'\\n'+link_time[0])\n",
    "        #try:\n",
    "            #mutex.acquire()\n",
    "        print('new news')\n",
    "        add_news(str(date), title, text, link_time[0], ag)\n",
    "        #finally:\n",
    "            #mutex.release()\n",
    "    except HTTPError:\n",
    "        print(\"No page found by this link!\",r.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 01 01\n",
      "ok\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) FATAL:  remaining connection slots are reserved for non-replication superuser connections\n (Background on this error at: http://sqlalche.me/e/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\n    return fn()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 400, in connect\n    return _ConnectionFairy._checkout(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 788, in _checkout\n    fairy = _ConnectionRecord.checkout(pool)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 529, in checkout\n    rec = pool._do_get()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 1193, in _do_get\n    self._dec_overflow()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/langhelpers.py\", line 66, in __exit__\n    compat.reraise(exc_type, exc_value, exc_tb)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py\", line 249, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 1190, in _do_get\n    return self._create_connection()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 347, in _create_connection\n    return _ConnectionRecord(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 474, in __init__\n    self.__connect(first_connect_check=True)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 671, in __connect\n    connection = pool._invoke_creator(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/strategies.py\", line 106, in connect\n    return dialect.connect(*cargs, **cparams)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/default.py\", line 412, in connect\n    return self.dbapi.connect(*cargs, **cparams)\n  File \"/usr/local/lib/python3.5/dist-packages/psycopg2/__init__.py\", line 130, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\npsycopg2.OperationalError: FATAL:  remaining connection slots are reserved for non-replication superuser connections\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-5-9bab34d8c0d2>\", line 14, in get_info\n    add_news(str(date), title, text, link_time[0], ag)\n  File \"/home/ostapkharysh/Documents/bachelor_thesis/manager.py\", line 55, in add_news\n    cur_agency = session.query(Agency).filter_by(name=agency_name).first()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 2895, in first\n    ret = list(self[0:1])\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 2687, in __getitem__\n    return list(res)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 2995, in __iter__\n    return self._execute_and_instances(context)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 3016, in _execute_and_instances\n    close_with_result=True)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 3025, in _get_bind_args\n    **kw\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/query.py\", line 3007, in _connection_from_session\n    conn = self.session.connection(**kw)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py\", line 1035, in connection\n    execution_options=execution_options)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py\", line 1040, in _connection_for_bind\n    engine, execution_options)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py\", line 409, in _connection_for_bind\n    conn = bind.contextual_connect()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py\", line 2123, in contextual_connect\n    self._wrap_pool_connect(self.pool.connect, None),\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py\", line 2162, in _wrap_pool_connect\n    e, dialect, self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception_noconnection\n    exc_info\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py\", line 265, in raise_from_cause\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py\", line 248, in reraise\n    raise value.with_traceback(tb)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\n    return fn()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 400, in connect\n    return _ConnectionFairy._checkout(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 788, in _checkout\n    fairy = _ConnectionRecord.checkout(pool)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 529, in checkout\n    rec = pool._do_get()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 1193, in _do_get\n    self._dec_overflow()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/langhelpers.py\", line 66, in __exit__\n    compat.reraise(exc_type, exc_value, exc_tb)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py\", line 249, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 1190, in _do_get\n    return self._create_connection()\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 347, in _create_connection\n    return _ConnectionRecord(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 474, in __init__\n    self.__connect(first_connect_check=True)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/pool.py\", line 671, in __connect\n    connection = pool._invoke_creator(self)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/strategies.py\", line 106, in connect\n    return dialect.connect(*cargs, **cparams)\n  File \"/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/default.py\", line 412, in connect\n    return self.dbapi.connect(*cargs, **cparams)\n  File \"/usr/local/lib/python3.5/dist-packages/psycopg2/__init__.py\", line 130, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  remaining connection slots are reserved for non-replication superuser connections\n (Background on this error at: http://sqlalche.me/e/e3q8)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e0b31c82742f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0;31m#except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0;31m#print(\"Terminating the pool\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) FATAL:  remaining connection slots are reserved for non-replication superuser connections\n (Background on this error at: http://sqlalche.me/e/e3q8)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n",
      "new news\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        for d in days:\n",
    "            try:\n",
    "                print(y, m, d)\n",
    "                datetime.datetime(year=int(y),month=int(m),day=int(d))\n",
    "                r = requests.get(link.format(y, m, d), timeout=5)\n",
    "                if r.ok: # check if page found\n",
    "                    print('ok')\n",
    "                    soup = BS(r.content, 'html.parser')\n",
    "                    span_list = soup.find_all('div' , attrs={'class':\"headlineMed\"})\n",
    "                    header = str(soup.find_all('title')).split()\n",
    "                    day, month, year = header[6], header[7], header[8]\n",
    "\n",
    "                    links_times = [[str(el).split('>')[1].split(\"=\")[1].replace('\"', ''), str(el).split()[-2]] for el in span_list \n",
    "                                   if not str(el).split('>')[1].split(\"=\")[1].replace('\"', '').startswith('http://www.reuters.com/news/video')]\n",
    "                    \n",
    "                    infer=partial(get_info, date=[day, month, year])\n",
    "                    pool = Pool(processes=10)\n",
    "                    pool.map(infer, links_times)\n",
    "                    #except:\n",
    "                        #print(\"Terminating the pool\")\n",
    "                        #pool.terminate() \n",
    "            except HTTPError:\n",
    "                print(\"No page found by this link!\",r.status)\n",
    "                continue\n",
    "            except ValueError:\n",
    "                print(\"Day doesn't exist\")\n",
    "                continue\n",
    "                    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    r = requests.get('https://www.reuters.com/resources/archive/us/20140111.html')\n",
    "    r.raise_for_status()\n",
    "except HTTPError:\n",
    "    print(\"No page found by this link! \"+ str(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['01', 'May', '2014']\n",
    "t = '11:59PM'\n",
    "date = datetime.datetime.strptime(\"{} {} {} {}\".format(d[1], d[0], d[-1], t), '%b %d %Y %I:%M%p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 5, 1, 23, 59)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
